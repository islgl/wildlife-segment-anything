{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:35:18.108187Z",
     "start_time": "2024-01-22T11:35:18.099651Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "import json\n",
    "\n",
    "from yolov5 import run as yolo_run\n",
    "from segment_anything import sam_register, sam_run\n",
    "from segment_anything.utils import get_masked_images\n",
    "from mobilenet.utils import preprocess\n",
    "from mobilenet import run as mobilenet_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = '/Users/lgl/code/machine_learning/wildlife-segment-anything/config/inference.yaml'\n",
    "with open(config_path) as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:29:14.907839Z",
     "start_time": "2024-01-22T11:29:14.902518Z"
    }
   },
   "id": "99cebbdab1afb69d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5 ðŸš€ 2024-1-19 Python-3.8.18 torch-2.1.2 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n",
      "image 1/10 /Users/lgl/code/machine_learning/wildlife-segment-anything/data/images/coco/bear.jpg: 480x640 1 bear, 260.9ms\n",
      "image 2/10 /Users/lgl/code/machine_learning/wildlife-segment-anything/data/images/coco/bird.jpg: 576x640 1 bird, 308.6ms\n",
      "image 3/10 /Users/lgl/code/machine_learning/wildlife-segment-anything/data/images/coco/cat.jpg: 448x640 1 cat, 244.4ms\n",
      "image 4/10 /Users/lgl/code/machine_learning/wildlife-segment-anything/data/images/coco/cow.jpg: 384x640 2 cows, 216.3ms\n",
      "image 5/10 /Users/lgl/code/machine_learning/wildlife-segment-anything/data/images/coco/dog.jpg: 448x640 2 dogs, 237.6ms\n",
      "image 6/10 /Users/lgl/code/machine_learning/wildlife-segment-anything/data/images/coco/elephant.jpg: 480x640 1 elephant, 256.5ms\n",
      "image 7/10 /Users/lgl/code/machine_learning/wildlife-segment-anything/data/images/coco/giraffe.jpg: 448x640 1 giraffe, 232.3ms\n",
      "image 8/10 /Users/lgl/code/machine_learning/wildlife-segment-anything/data/images/coco/horse.jpg: 384x640 1 horse, 207.6ms\n",
      "image 9/10 /Users/lgl/code/machine_learning/wildlife-segment-anything/data/images/coco/sheep.jpg: 640x448 1 dog, 2 sheeps, 245.9ms\n",
      "image 10/10 /Users/lgl/code/machine_learning/wildlife-segment-anything/data/images/coco/zebra.jpg: 480x640 1 zebra, 250.5ms\n",
      "Speed: 1.1ms pre-process, 246.0ms inference, 1.0ms NMS per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Run YOLOv5 inference\n",
    "prompts = yolo_run(\n",
    "    weights=config['yolo'],\n",
    "    source=config['dataset'],\n",
    "    data=config['config'],\n",
    "    device=config['device'],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:29:18.608712Z",
     "start_time": "2024-01-22T11:29:14.909715Z"
    }
   },
   "id": "a238c0105fd88045"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1/10 images\n",
      "Processed 2/10 images\n",
      "Processed 3/10 images\n",
      "Processed 4/10 images\n",
      "Processed 5/10 images\n",
      "Processed 6/10 images\n",
      "Processed 7/10 images\n",
      "Processed 8/10 images\n",
      "Processed 9/10 images\n",
      "Processed 10/10 images\n"
     ]
    }
   ],
   "source": [
    "# Run SAM inference\n",
    "sam = sam_register(\n",
    "    checkpoint=config['sam_checkpoint'],\n",
    "    model_type=config['sam_model_type'],\n",
    "    device=config['device'],\n",
    ")\n",
    "masks = sam_run(\n",
    "    dataset=config['dataset'],\n",
    "    prompt=prompts,\n",
    "    predictor=sam,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:31:52.023784Z",
     "start_time": "2024-01-22T11:29:18.609220Z"
    }
   },
   "id": "1ddd1111222247b8"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Get masked images\n",
    "masked_images = get_masked_images(\n",
    "    dataset=config['dataset'],\n",
    "    masks=masks,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:31:52.085018Z",
     "start_time": "2024-01-22T11:31:52.026326Z"
    }
   },
   "id": "ff8ef0143fc1c587"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Run MobileNet inference\n",
    "# Load MobileNet model\n",
    "mobilenet = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True)\n",
    "mobilenet.eval()\n",
    "\n",
    "# Preprocess images\n",
    "mobilenet_input = preprocess(masked_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:31:52.204772Z",
     "start_time": "2024-01-22T11:31:52.083799Z"
    }
   },
   "id": "25ebbe8241c2e6f"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Using cache found in /Users/lgl/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "# Run inference\n",
    "results = mobilenet_run(\n",
    "    input_batches=mobilenet_input,\n",
    "    label_path=config['labels'],\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:34:21.799727Z",
     "start_time": "2024-01-22T11:34:20.463142Z"
    }
   },
   "id": "4ef72581fbecb58f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "{'dog.jpg': {'flat-coated retriever': 0.3171379566192627},\n 'horse.jpg': {'African elephant': 0.18369567394256592},\n 'elephant.jpg': {'Indian elephant': 0.6400818228721619},\n 'zebra.jpg': {'zebra': 0.8779024481773376},\n 'sheep.jpg': {'ox': 0.3848831355571747},\n 'bird.jpg': {'indigo bunting': 0.19207172095775604},\n 'cow.jpg': {'Chihuahua': 0.15208041667938232},\n 'cat.jpg': {'Arctic fox': 0.6235840320587158},\n 'giraffe.jpg': {'banded gecko': 0.3448532521724701},\n 'bear.jpg': {'ice bear': 0.21838708221912384}}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:34:24.584017Z",
     "start_time": "2024-01-22T11:34:24.569994Z"
    }
   },
   "id": "416bbe0450754f6e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "with open('/Users/lgl/code/machine_learning/wildlife-segment-anything/results/results.json','w') as f:\n",
    "    json.dump(results, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T11:35:21.486650Z",
     "start_time": "2024-01-22T11:35:21.475721Z"
    }
   },
   "id": "31a66318498d73"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
